<!doctype html><html lang=en><head><title>Karaf clustering using Hazelcast · Ioannis Canellos - My Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Ioannis Canellos"><meta name=description content="EDIT: The project “cellar” has been upgraded with a lot new features, which are not described by this post. A new post will be added soon.
Prologue Link to heading I have been playing a lot with Hazelcast lately, especially pairing it with Karaf. If you haven’t done already you can read my previous post on using Hazelcast on Karaf.
In this post I am going to take things one step further and use Hazelcast to build a simple clustering engine on Karaf."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Karaf clustering using Hazelcast"><meta name=twitter:description content="EDIT: The project “cellar” has been upgraded with a lot new features, which are not described by this post. A new post will be added soon.
Prologue Link to heading I have been playing a lot with Hazelcast lately, especially pairing it with Karaf. If you haven’t done already you can read my previous post on using Hazelcast on Karaf.
In this post I am going to take things one step further and use Hazelcast to build a simple clustering engine on Karaf."><meta property="og:title" content="Karaf clustering using Hazelcast"><meta property="og:description" content="EDIT: The project “cellar” has been upgraded with a lot new features, which are not described by this post. A new post will be added soon.
Prologue Link to heading I have been playing a lot with Hazelcast lately, especially pairing it with Karaf. If you haven’t done already you can read my previous post on using Hazelcast on Karaf.
In this post I am going to take things one step further and use Hazelcast to build a simple clustering engine on Karaf."><meta property="og:type" content="article"><meta property="og:url" content="https://iocanel.github.io/2011/03/karaf-clustering-using-hazelcast/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2011-03-11T00:00:00+02:00"><meta property="article:modified_time" content="2011-03-11T00:00:00+02:00"><link rel=canonical href=https://iocanel.github.io/2011/03/karaf-clustering-using-hazelcast/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.c4d7e93a158eda5a65b3df343745d2092a0a1e2170feeec909b8a89443903c6a.css integrity="sha256-xNfpOhWO2lpls980N0XSCSoKHiFw/u7JCbiolEOQPGo=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.78b5fe3864945faf5207fb8fe3ab2320d49c3365def0e88ac1df0ddadc54a03c.css integrity="sha256-eLX+OGSUX69SB/uP46sjINScM2Xe8OiKwd8N2txUoDw=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.105.0"></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Ioannis Canellos - My Blog</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>blog</a></li><li class=navigation-item><a class=navigation-link href=/about/>about</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://iocanel.github.io/2011/03/karaf-clustering-using-hazelcast/>Karaf clustering using Hazelcast</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2011-03-11T00:00:00+02:00>March 11, 2011</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
5-minute read</span></div></div></header><div><p><strong><strong>EDIT</strong></strong>: The project “cellar” has been upgraded with a lot new features, which are not described by this post. A new post will be added soon.</p><h2 id=prologue>Prologue
<a class=heading-link href=#prologue><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>I have been playing a lot with <a href=https://hazelcast.com/>Hazelcast</a> lately, especially pairing it with Karaf. If you haven’t done already you can read my previous post on using Hazelcast on Karaf.</p><p>In this post I am going to take things one step further and use Hazelcast to build a simple clustering engine on Karaf.</p><p>The engine that I am going to build will have the following features:</p><ul><li><strong><strong>Zero configuration clustering</strong></strong><ul><li>Node discover each other with no config</li></ul></li><li><strong><strong>Configuration Replication</strong></strong><ul><li>muslticasting configuration change events</li><li>configurable blacklist/whitelist by PID</li><li>lifecycel support (can be enabled/disabled using shell)</li></ul></li><li><strong><strong>Features Repository & State replication</strong></strong><ul><li>multicasting repository events (add url and remove url).</li><li>multicasting features state events.</li><li>configurable blacklist / whitelist by feature.</li><li>lifecycle support (can be enabled/disabled using shell).</li></ul></li><li><strong><strong>Clustering management</strong></strong><ul><li>distributed command pattern implementation.</li><li>monitoring and management commands.</li></ul></li></ul><h2 id=architecture>Architecture
<a class=heading-link href=#architecture><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>The idea behind the clustering engine is that for each unit that we want to replicate, we create an event, broadcast the event to the cluster and hold the unit state to a shared resource, so that the rest of the nodes can look up and retrieve the changes.</p><figure><img src=architecture.png></figure><p><strong><strong>Example</strong></strong>: We want all nodes in our cluster to share configuration for PIDs a.b.c and x.y.z. On node “Karaf A” a change occurs on a.b.c. “Karaf A” updates the shared repository data for a.b.c and then notifies the rest of the nodes that a.b.c has changed. Each node looks up the shared repository and retrieves changes.</p><h2 id=the-role-of-hazelcast>The role of Hazelcast
<a class=heading-link href=#the-role-of-hazelcast><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>The architecture as described so far could be implemented using a database/shared filesystem as a shared resource and polling instead of multicasting events. So why use Hazelcast?
Hazelcast fits in perfectly because it offers:</p><ul><li><strong><strong>Auto discovery</strong></strong><ul><li>Cluster nodes can discover each other automatically.</li><li>No configuration is required.</li></ul></li><li><strong><strong>No single point of failure</strong></strong><ul><li>No server or master is required for clustering.</li><li>The shared resource is distributed, hence we introduce no single point of failure.</li></ul></li><li><strong><strong>Provides distributed topics</strong></strong><ul><li>Using in memory distributed topics allows us to broadcast events / commands the are valuable for management and monitoring.</li></ul></li></ul><h3 id=the-implementation>The implementation
<a class=heading-link href=#the-implementation><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>For implementing all the above we have the following entities:</p><h4 id=osgi-listener>OSGi Listener
<a class=heading-link href=#osgi-listener><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>An interface the implements a listener for specific OSGi events (e.g. ConfigurationListener)</p><h4 id=event>Event
<a class=heading-link href=#event><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>The object that contains all the required information required to describe the event (e.g. PID changed).</p><h4 id=event-topic>Event Topic
<a class=heading-link href=#event-topic><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>The distributed topic use to broadcast events. It is common for all event types.</p><h4 id=shared-map>Shared Map
<a class=heading-link href=#shared-map><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>The distributed collection the serves as shared resource. We use one per event type.</p><h4 id=event-handler>Event Handler
<a class=heading-link href=#event-handler><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>The processor the processes remote event received through the topic.</p><h4 id=event-dispatcher>Event Dispatcher
<a class=heading-link href=#event-dispatcher><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>The unit the decides which event should be processed by which event handlers.</p><h4 id=command>Command
<a class=heading-link href=#command><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>A special type of event that is linked to a list of events that represent the outcome of the command.</p><h4 id=result>Result
<a class=heading-link href=#result><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h4><p>A special type of event that represents the outcome of a command. Commands and results are correlated.</p><p><img src=event+flow.png alt>
The OSGi spec in a lot of situations describe Events and Listener (e.g. ConfigurationChangeEvent and ConfigurationListener).By implementing such Listener and expose it as an OSGi service to the Service Registry I make sure that we “listen” to the events of interest.</p><p>When the listener is notified of an event it forwards the Event object to a Hazel cast distributed topic. To keep things as simple as possible I keep a single topic for all event types. Each node has a listener registered on that topic and gets sends all events to the event Dispatcher.</p><p>The Event Dispathcer when receives an event it looks up an internal registry (in our case the OSGi Service Registry), in order to find and Event Handler that can handle the received Event. If a handler is found then it receives the event and processes it.</p><h2 id=broadcasting-commands>Broadcasting commands
<a class=heading-link href=#broadcasting-commands><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Commands are a special kind of events. They imply that when they are handled a Result event will be fired, that will contain the outcome of the command. So for each command we have one result per recipient. Each command contains a unique id (unique foe all cluster nodes, create from Hazelcast). This id is used to correlate the request with the result. For each result successfully correlated the result is added to list of results on the command object. If the list gets full or if 10 seconds from the command execution have elapsed, the list is moved to a blocking queue from which the result can be retrieved.</p><p>The snippet below shows what happens when a command is sent for execution.</p><h2 id=using-the-source>Using the source
<a class=heading-link href=#using-the-source><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>I created a small project that demonstrates all of the functionality described above and have uploaded it to github, so that I can share it with you, receive feedback and discuss about it. The project is called cellar. I couldn’t find a more appropriate name to give to a cluster of Karafs.</p><p>Once you build the source you can install it as a karaf feature and then you are ready to use the cluster shell commands.</p><figure><img src=consoles.png></figure><p>In the image above I start two karaf instances, I install cellar to both and then I list the cluster members and I disable the configuration event handler of the first node.
The rest is up to you to explore,
Enjoy!</p></div><footer></footer></article></section></div><footer class=footer><section class=container>©
2019 -
2022
Ioannis Canellos
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js integrity="sha256-I2BJOV3DaC+ycZZAhylY4S8fJAZ7sJwyeyM+YpDH7aw="></script></body></html>